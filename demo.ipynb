{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# from lanchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "        prompt=PromptTemplate(\n",
    "            # template=\"What is a good name for a company that makes {product}? Answer in complete sentence\",\n",
    "            template=\"Question: What is a good name for a company that makes {product}? Answer:\",\n",
    "            input_variables=[\"product\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
    "# print(chain.run(\"stupid AI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_role_defining = '''\n",
    "You are an interviewer. You are interviewing a candidate for a job. You and the candidate will be given a business case.\n",
    "The goal of the interview is to solve the business case together with the candidate, but you will only be giving necessary hints to the candidate (according to the given case information), and you would not make anything up.\n",
    "The given case is :\n",
    "{case}.\n",
    "If you understand your role, please say \"I am an interviewer and let the show start!\"\n",
    "'''\n",
    "case_1 = \"A company is looking to expand its business. What should it do?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatBot Demo\n",
    "The following part is essentially a temperature = 0.9 `gpt-3.5-turbo` chatbot, with limited memory (`4096 tokens max`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'case'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m chat_prompt \u001b[39m=\u001b[39m ChatPromptTemplate\u001b[39m.\u001b[39mfrom_messages([system_message_prompt, human_message_prompt])\n\u001b[1;32m     12\u001b[0m \u001b[39m# get a chat completion from the formatted messages\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m chat(chat_prompt\u001b[39m.\u001b[39;49mformat_prompt(input_language\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEnglish\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_language\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mFrench\u001b[39;49m\u001b[39m\"\u001b[39;49m, text\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mI love programming.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mto_messages())\n\u001b[1;32m     14\u001b[0m \u001b[39m# interview_prompt.format(case=case_1) # for debugging\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39m# memory object defined for debugging\u001b[39;00m\n\u001b[1;32m     18\u001b[0m conver_memory \u001b[39m=\u001b[39m ConversationBufferMemory()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/langchain/prompts/chat.py:127\u001b[0m, in \u001b[0;36mBaseChatPromptTemplate.format_prompt\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_prompt\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PromptValue:\n\u001b[0;32m--> 127\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_messages(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatPromptValue(messages\u001b[39m=\u001b[39mmessages)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/langchain/prompts/chat.py:186\u001b[0m, in \u001b[0;36mChatPromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(message_template, BaseMessagePromptTemplate):\n\u001b[1;32m    181\u001b[0m     rel_params \u001b[39m=\u001b[39m {\n\u001b[1;32m    182\u001b[0m         k: v\n\u001b[1;32m    183\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    184\u001b[0m         \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m message_template\u001b[39m.\u001b[39minput_variables\n\u001b[1;32m    185\u001b[0m     }\n\u001b[0;32m--> 186\u001b[0m     message \u001b[39m=\u001b[39m message_template\u001b[39m.\u001b[39;49mformat_messages(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrel_params)\n\u001b[1;32m    187\u001b[0m     result\u001b[39m.\u001b[39mextend(message)\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/langchain/prompts/chat.py:75\u001b[0m, in \u001b[0;36mBaseStringMessagePromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_messages\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[BaseMessage]:\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/langchain/prompts/chat.py:106\u001b[0m, in \u001b[0;36mSystemMessagePromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 106\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt\u001b[39m.\u001b[39;49mformat(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m SystemMessage(content\u001b[39m=\u001b[39mtext, additional_kwargs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madditional_kwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/langchain/prompts/prompt.py:66\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m    prompt.format(variable1=\"foo\")\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_partial_and_user_variables(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 66\u001b[0m \u001b[39mreturn\u001b[39;00m DEFAULT_FORMATTER_MAPPING[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemplate_format](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemplate, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/string.py:163\u001b[0m, in \u001b[0;36mFormatter.format\u001b[0;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, format_string, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvformat(format_string, args, kwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/langchain/formatting.py:29\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     26\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo arguments should be provided, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39meverything should be passed as keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[0;32m---> 29\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mvformat(format_string, args, kwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/string.py:167\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvformat\u001b[39m(\u001b[39mself\u001b[39m, format_string, args, kwargs):\n\u001b[1;32m    166\u001b[0m     used_args \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m--> 167\u001b[0m     result, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vformat(format_string, args, kwargs, used_args, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m    168\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/string.py:207\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[0;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[1;32m    203\u001b[0m     auto_arg_index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m# given the field_name, find the object it references\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m#  and the argument it came from\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m obj, arg_used \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_field(field_name, args, kwargs)\n\u001b[1;32m    208\u001b[0m used_args\u001b[39m.\u001b[39madd(arg_used)\n\u001b[1;32m    210\u001b[0m \u001b[39m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/string.py:272\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[0;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_field\u001b[39m(\u001b[39mself\u001b[39m, field_name, args, kwargs):\n\u001b[1;32m    270\u001b[0m     first, rest \u001b[39m=\u001b[39m _string\u001b[39m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[0;32m--> 272\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_value(first, args, kwargs)\n\u001b[1;32m    274\u001b[0m     \u001b[39m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[39m#  getattr or getitem as needed\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[39mfor\u001b[39;00m is_attr, i \u001b[39min\u001b[39;00m rest:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/string.py:229\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[0;34m(self, key, args, kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m args[key]\n\u001b[1;32m    228\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mreturn\u001b[39;00m kwargs[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'case'"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "# ConversationBufferMemory would significantly increase the Token usage if the converstaion is to be long, for example in the case-interivew project.\n",
    "\n",
    "template=prompt_role_defining\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template=\"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# get a chat completion from the formatted messages\n",
    "chat(chat_prompt.format_prompt(input_language=\"English\", output_language=\"French\", text=\"I love programming.\").to_messages())\n",
    "# interview_prompt.format(case=case_1) # for debugging\n",
    "\n",
    "\n",
    "# memory object defined for debugging\n",
    "conver_memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=conver_memory,\n",
    "    prompt=chat_prompt(case=case_1),\n",
    "    # setting verbose=True will log the entire conversation.\n",
    "    verbose = False\n",
    ")\n",
    "\n",
    "\n",
    "# chatbot realization\n",
    "\n",
    "user_input = 0\n",
    "while user_input != \"quit\":\n",
    "\n",
    "    # print(conver_memory.load_memory_variables({})) # for debugging\n",
    "    \n",
    "    print(conversation.run(user_input))\n",
    "    user_input = input(\"Enter your message: \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I try to merge the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are an interviewer. You are interviewing a candidate for a job. You and the candidate will be given a business case.\\nThe goal of the interview is to solve the business case together with the candidate, but you will only be giving necessary hints to the candidate (according to the given case information), and you would not make anything up.\\nThe given case is A company is looking to expand its business. What should it do?.\\nIf you understand your role, please say \"I am an interviewer and let the show start!\"\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
